<html>
<head>
<title>Craigslist Scraper in Python</title>
</head>
<body style='background-color:LightGray;font-family:Arial, Helvetica, sans-serif;'>
<div style='width:800px; margin-left:auto; margin-right:auto;padding:30px;background-color:white;'>
<h3>Craigslist Scraper</h3>

<h4>The 'Why'</h4>
I wanted to be a freelance proofreader, and I realized I could find leads on the writing gigs section of Craigslist.

Obviously these jobs (mostly) don't require being local to the clients; I could find clients on any Craigslist subdomain.

Checking through every local Craigslist writing gigs section is the perfect task to be automated by software.

<h4>The 'How'</h4>

I originally created this as a PHP script, using <a href='http://simplehtmldom.sourceforge.net' target='_blank' >Simple HTML DOM</a> to help with parsing the HTML.  Then I lost some data which included that script.  So when I went to rebuild it, I did it in Python to "expand my horizons" and used <a href='http://www.crummy.com/software/BeautifulSoup/' target='_blank' >BeautifulSoup4</a> for HTML parsing.  It is written to be run daily as a cron job, and will only look for relevant postings from the day prior.

<h4>The Output</h4>

<a href='./2015-09-16.html' >Click here to view an example HTML file outputted by the script</a>.  Please note that after enough time has passed, none of the links in this page will still be valid Craigslist postings.

<h4>The Code</h4>

<a href='scrape.py.txt' >Click here to view the scraper code</a>.

<h4>Assumptions & Known Shortcomings</h4>

The script assumes that there is a file 'subdomains.txt' in the same directory as it, which lists  Craigslist subdomains.  It was built under the assumption that there are so few postings in every writing gigs section, that there won't be any that are missed by not navigating to the next page. In the python version of this script, Craigslist subdomains that haven't been encountered before will be added to the <em>./subdomains.txt</em> listing.  They will not, however, be checked during that same running of the script.  I could fix this by playing with the for loop controlling subdomain iteration but I've got so many other things I want to program instead.
</div>
<script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101143852);</script>
<script async src="//static.getclicky.com/js"></script>

</body>
</html>
