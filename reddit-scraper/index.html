<html>
<head>
<title>Reddit Comment Scraper in Python</title>
</head>
<body style='background-color:LightGray;font-family:Arial, Helvetica, sans-serif;'>
<div style='width:800px; margin-left:auto; margin-right:auto;padding:30px;background-color:white;'>
<h3>Reddit Comment Scraper</h3>

<h4>The 'Why'</h4>
When planning for my Estate Sale business, I spent a lot of time reading through the <a href="https://www.reddit.com/r/smallbusiness/" title="/r/smallbusiness" target="_blank" >smallbusiness subreddit</a>.  I would find some comments that were absolute gold; super good advice.  However, when looking for more advice from these users, sometimes they would have dozens of pages of comments in non-business related subreddits.  Rather than "searching for a needle in a haystack" by hand, I simply wrote this scraper.

<h4>The 'How'</h4>

A python script, utilizing <a href='http://www.crummy.com/software/BeautifulSoup/' target='_blank' >BeautifulSoup4</a> for HTML parsing.  Upon initialization, the user is prompted for the reddit account to scrape the comments of.  The script then pulls in all of their comments, and presents the user with a list of subreddits that comments were found in, as well as the tally of comments in that subreddit.  User inputs a listing of which subreddit comments they are interested in, and the script prints all of these comments to a local file for the user to peruse.

<h4>The Output</h4>

<a href='./reddit_scraper_output_sample.html' >Click here to view an example HTML file outputted by the script</a>.  The comments include a link to delete them from the page, so the user can save the page with all of the unhelpful comments pruned out.  Also, there is zebra-striping for comments in different subreddits.  Below you can view a screenshot of the script outputting the list of subreddits that the chosen user's comments are in.  Notice how subreddits #20 and #44 are the only ones which appear to have information relevant to my interests.
<br /><br />
<center><img src='./reddit_scraper_screenshot.png' /></center>

<h4>The Code</h4>

<a href='scrape.py.txt' >Click here to view the scraper code</a>.

<h4>Assumptions & Known Shortcomings</h4>

The script outputs the results file into the local directory, with the filename being the username whose comments were scraped.  This could be updated to prompt the user for a filename but this script suits my needs as is.

</div>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-69463665-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
